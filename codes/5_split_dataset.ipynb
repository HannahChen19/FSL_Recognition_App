{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform per class feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _framework_bindings: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hannah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\__init__.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 - 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hannah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020-2021 The MediaPipe Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Python API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_ckpt_util\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_util\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalculator_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CalculatorGraph\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _framework_bindings: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Input, Dense, GlobalAveragePooling1D, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "\n",
    "# Paths to video dataset\n",
    "VIDEO_PATH = \"../model_input/augmented_train_clips\"  # Update this\n",
    "OUTPUT_DIR = \"../model_input/output_features\"  # Directory to save per-class feature files\n",
    "ERROR_LOG_FILE = \"../model_input/output_features/error_log.txt\"\n",
    "\n",
    "# Initialize Mediapipe models\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Mediapipe Constants\n",
    "FACE_FEATURES = [33, 263, 61, 291, 199, 159, 145, 386, 374, 152]  # Eyebrows, eyes, and mouth\n",
    "MAX_HANDS = 2\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Function to extract labels from filenames\n",
    "def extract_label(filename):\n",
    "    match = re.search(r'^(.*_\\d+)_.*$', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Function to process a single video and extract features\n",
    "# Function to process a single video and extract features\n",
    "def extract_features_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    face_features = []\n",
    "    hand_features = []\n",
    "\n",
    "    prev_face_features = None  # Variable to store features from previous frame\n",
    "    prev_hand_features = None  # Variable to store features from previous frame\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1) as face_mesh, \\\n",
    "         mp_hands.Hands(static_image_mode=False, max_num_hands=2) as hands:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Face landmark detection\n",
    "            face_result = face_mesh.process(frame_rgb)\n",
    "            frame_face_features = []\n",
    "\n",
    "            if face_result.multi_face_landmarks:\n",
    "                for face_landmarks in face_result.multi_face_landmarks:\n",
    "                    for idx in FACE_FEATURES:\n",
    "                        landmark = face_landmarks.landmark[idx]\n",
    "                        frame_face_features.append([landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "            else:\n",
    "                if prev_face_features is not None:\n",
    "                    frame_face_features = prev_face_features\n",
    "                else:\n",
    "                    frame_face_features = [[0, 0, 0]] * len(FACE_FEATURES)\n",
    "\n",
    "            face_features.append(frame_face_features)\n",
    "            prev_face_features = frame_face_features  # Save for the next iteration\n",
    "\n",
    "            # Hand landmark detection\n",
    "            hand_result = hands.process(frame_rgb)\n",
    "            frame_hand_features = []\n",
    "\n",
    "            if hand_result.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_result.multi_hand_landmarks:\n",
    "                    for idx in range(21):  # 21 hand landmarks\n",
    "                        landmark = hand_landmarks.landmark[idx]\n",
    "                        frame_hand_features.append([landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "            else:\n",
    "                if prev_hand_features is not None:\n",
    "                    frame_hand_features = prev_hand_features\n",
    "                else:\n",
    "                    frame_hand_features = [[0, 0, 0]] * (21 * MAX_HANDS)\n",
    "\n",
    "            if len(frame_hand_features) < (21 * MAX_HANDS):\n",
    "                pad_length = (21 * MAX_HANDS) - len(frame_hand_features)\n",
    "                frame_hand_features.extend([[0, 0, 0]] * pad_length)\n",
    "\n",
    "            hand_features.append(frame_hand_features)\n",
    "            prev_hand_features = frame_hand_features  # Save for the next iteration\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    # Convert to numpy arrays and enforce consistent shapes\n",
    "    face_features = np.array(face_features, dtype=np.float32)\n",
    "    hand_features = np.array(hand_features, dtype=np.float32)\n",
    "\n",
    "    # Padding or trimming to ensure consistent number of frames\n",
    "    min_len = min(len(face_features), len(hand_features))\n",
    "    face_features = face_features[:min_len]\n",
    "    hand_features = hand_features[:min_len]\n",
    "\n",
    "    # Padding the shorter sequence to match the longer one\n",
    "    max_len = max(len(face_features), len(hand_features))\n",
    "    if len(face_features) < max_len:\n",
    "        padding = np.zeros((max_len - len(face_features), face_features.shape[1], 3))\n",
    "        face_features = np.vstack([face_features, padding])\n",
    "    if len(hand_features) < max_len:\n",
    "        padding = np.zeros((max_len - len(hand_features), hand_features.shape[1], 3))\n",
    "        hand_features = np.vstack([hand_features, padding])\n",
    "\n",
    "    # Temporal smoothing and structuring using 1D convolution or LSTM\n",
    "    smoothed_face_features = apply_temporal_smoothing(face_features)\n",
    "    smoothed_hand_features = apply_temporal_smoothing(hand_features)\n",
    "\n",
    "    try:\n",
    "        combined_features = np.hstack([ \n",
    "            smoothed_face_features.reshape(max_len, -1),\n",
    "            smoothed_hand_features.reshape(max_len, -1)\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature stacking: {str(e)}\")\n",
    "        combined_features = np.zeros((max_len, len(FACE_FEATURES) * 3 + (21 * MAX_HANDS) * 3))\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "# Function to apply temporal smoothing using convolution or LSTM\n",
    "# Function to apply temporal smoothing using convolution or LSTM\n",
    "def apply_temporal_smoothing(features):\n",
    "    features = np.reshape(features, (features.shape[0], -1))\n",
    "    features = np.expand_dims(features, axis=-1)  # Shape: (num_frames, num_features, 1)\n",
    "    \n",
    "    conv_layer = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(features)\n",
    "    smoothed_features = GlobalAveragePooling1D()(conv_layer)\n",
    "    smoothed_features = smoothed_features.numpy()\n",
    "\n",
    "    return smoothed_features\n",
    "\n",
    "\n",
    "# Function to save features by input file\n",
    "def save_features_by_class(features, label, filename):\n",
    "    # Remove file extension from the original filename\n",
    "    '''\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Check if the filename contains any augmentation-related words\n",
    "    augmentations = ['blurred', 'brightened', 'flipped', 'scaled', 'sharpened', 'shifted']\n",
    "    if any(word in filename_without_extension for word in augmentations):\n",
    "        # Get the part before the last underscore\n",
    "        pkl_filename = \"_\".join(filename_without_extension.split('_')[:-1]) + \".pkl\"\n",
    "    else:\n",
    "        # Keep the original filename as is\n",
    "        pkl_filename = filename_without_extension + \".pkl\"\n",
    "    '''\n",
    "\n",
    "    pkl_filename = os.path.splitext(filename)[0]\n",
    "\n",
    "    class_filename = os.path.join(OUTPUT_DIR, pkl_filename)\n",
    "\n",
    "    if os.path.exists(class_filename):\n",
    "        # Append to existing file\n",
    "        with open(class_filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        existing_features = data['features']\n",
    "        existing_features.append(features)\n",
    "        data['features'] = existing_features\n",
    "    else:\n",
    "        # Create new file\n",
    "        data = {'features': [features], 'label': label}\n",
    "\n",
    "    # Save updated data\n",
    "    with open(class_filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "# Main processing\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    for file in os.listdir(VIDEO_PATH):\n",
    "        if file.endswith(('.MP4', '.MOV')):\n",
    "            print(f\"Processing {file}...\")\n",
    "            video_file_path = os.path.join(VIDEO_PATH, file)\n",
    "            label = extract_label(file)\n",
    "            \n",
    "            try:\n",
    "                features = extract_features_from_video(video_file_path)\n",
    "                save_features_by_class(features, label, file)\n",
    "            \n",
    "            except Exception as e:\n",
    "                with open(ERROR_LOG_FILE, \"a\") as log_file:\n",
    "                    log_file.write(f\"Error processing file {file}: {str(e)}\\n\")\n",
    "                print(f\"Error processing {file}, logged to {ERROR_LOG_FILE}.\")\n",
    "    \n",
    "    print(\"Feature extraction complete. Features saved per input file.\")\n",
    "'''\n",
    "\n",
    "# Main processing\n",
    "if __name__ == \"__main__\":\n",
    "    # Get all files in the directory\n",
    "    files = [file for file in os.listdir(VIDEO_PATH) if file.endswith(('.MP4', '.MOV'))]\n",
    "\n",
    "    # Sort the files alphabetically and find the index of 'dont_understand_15'\n",
    "    files.sort()\n",
    "    \n",
    "    start_processing = False  # Flag to start processing from 'dont_understand_15'\n",
    "\n",
    "    for file in files:\n",
    "        if not start_processing:\n",
    "            if 'hot_16' in file:  # Start processing from 'dont_understand_15'\n",
    "                start_processing = True\n",
    "        \n",
    "        if start_processing:\n",
    "            print(f\"Processing {file}...\")\n",
    "            video_file_path = os.path.join(VIDEO_PATH, file)\n",
    "            label = extract_label(file)\n",
    "            \n",
    "            try:\n",
    "                features = extract_features_from_video(video_file_path)\n",
    "                save_features_by_class(features, label, file)\n",
    "            \n",
    "            except Exception as e:\n",
    "                with open(ERROR_LOG_FILE, \"a\") as log_file:\n",
    "                    log_file.write(f\"Error processing file {file}: {str(e)}\\n\")\n",
    "                print(f\"Error processing {file}, logged to {ERROR_LOG_FILE}.\")\n",
    "    \n",
    "    print(\"Feature extraction complete. Features saved per input file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
